{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy data\n",
    "\n",
    "\"Tidy data\" is a term coined by Hadley Wickam to describe data structured such that each variable is a column, each observation is a row, and each type of observational unit is a table [(Wickham, 2014)](http://dx.doi.org/10.18637/jss.v059.i10).\n",
    "Data following this structure is much easier to investigate.\n",
    "\n",
    "This Jupyter notebook works through the examples in the tidy data paper in pandas, using data sets from the [tidy data Github repository](https://github.com/hadley/tidy-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nu\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining tidy data\n",
    "\n",
    "Here is some example data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preg = pd.read_csv('data/preg-raw.csv', header=None)\n",
    "preg.columns = 'person treatment_a treatment_b'.split()\n",
    "preg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different way to look at the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.pivot_table(preg, columns='person')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the tidy version of the same data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.melt(preg, id_vars='person', var_name='treatment', value_name='result')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again,\n",
    "\n",
    "1. Each variable forms a column.\n",
    "2. Each observation forms a row.\n",
    "3. Each type of observational unit forms a table."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tidying messy datasets\n",
    "\n",
    "### Column headers are values, not variable names\n",
    "\n",
    "Here we see a table from a Pew research study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pew = pd.read_csv('data/pew-raw.csv')\n",
    "pew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be a convenient form for data, but it is not tidy data.\n",
    "Here we can tidy it by melting.\n",
    "Melting is parameterized by a list of columns that are already variables, or _colvars_ for short. \n",
    "The other columns are converted into two variables: a new variable called `income` that contains repeated column headings, and another called `freq` that contains the concatenated data values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.melt(pew, id_vars=['religion'], var_name='income', value_name='freq').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Billboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "billboard = pd.read_csv('data/billboard.csv')\n",
    "billboard.iloc[:4, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tidy_billboard = pd.melt(\n",
    "    billboard, \n",
    "    id_vars='year artist time genre track date.entered date.peaked'.split(),\n",
    "    var_name='week',\n",
    "    value_name='rank')\n",
    "tidy_billboard['week'] = map(lambda s: int(s.lstrip('wk')), tidy_billboard['week'])\n",
    "tidy_billboard['date'] = \\\n",
    "    pd.to_datetime(tidy_billboard['date.entered']) \\\n",
    "    + pd.Series(map(lambda w: pd.DateOffset(weeks=w), tidy_billboard['week']))\n",
    "tidy_billboard.pop('date.entered')\n",
    "tidy_billboard.pop('date.peaked')\n",
    "tidy_billboard.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tb = pd.read_csv('data/tb.csv')\n",
    "for col in 'new_sp mu fu'.split():\n",
    "    tb.pop(col)\n",
    "tb.rename(columns={'iso2': 'country'}, inplace=True)\n",
    "molten_tb = pd.melt(tb, id_vars='country year'.split(), var_name='column', value_name='cases')\n",
    "molten_tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_codes = '''\n",
    "04 0-4\n",
    "514 5-14\n",
    "014 0-14\n",
    "1524 15-24\n",
    "2534 25-34\n",
    "3544 35-44\n",
    "4554 45-54\n",
    "5564 55-64\n",
    "65 65+\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "date_code_dict = {r[0]: r[1] for r in [s.split() for s in date_codes.strip().split('\\n')]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tidy_tb = molten_tb.copy()\n",
    "tidy_tb['sex'] = [s[0] for s in tidy_tb['column']]\n",
    "tidy_tb['age'] = [date_code_dict[s[1:]] for s in tidy_tb['column']]\n",
    "tidy_tb.pop('column')\n",
    "tidy_tb.loc[pd.isnull(tidy_tb['cases']), 'cases'] = 0\n",
    "tidy_tb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weather\n",
    "\n",
    "The formatting for this data set is completely crazy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather = pd.read_table(\n",
    "    'data/weather.tsv', \n",
    "    sep=' [ ]*I[ ]*', \n",
    "    names=['info']+['d'+str(d) for d in range(2, 33)])\n",
    "splut = [s.split() for s in weather['info']]\n",
    "weather['info'] = [s[0] for s in splut]\n",
    "weather['d1'] = [s[1] for s in splut]\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that there's nothing interesting happening in the artifactual day 32 column, then drop it.\n",
    "Replace those silly -9999's with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert(np.all(pd.isnull(weather['d32'])))\n",
    "weather.pop('d32')\n",
    "for d in 'd29 d30'.split():\n",
    "    weather.loc[weather[d] == '-9999   -9999', d] = np.nan\n",
    "weather.loc[weather['d31'] == -9999, 'd31'] = np.nan\n",
    "print list(weather.iloc[0])\n",
    "print list(weather.iloc[31])\n",
    "\n",
    "weather = weather[['info']+['d'+str(d) for d in range(1, 32)]]  # Reorder columns.\n",
    "weather.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
